{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Novel Convolutional Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we present a novel attention mechanism that is core in our current research. This mechanism allows for hierarchical attention to various regious of the data, and can learn invariance to feature position, scale, and pose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_images = np.random.uniform(size=[32, 57, 57, 3])\n",
    "image_labels = np.random.uniform(size=[32, 1000])\n",
    "g = tf.Graph()\n",
    "sess = tf.Session(graph=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "\n",
    "    with tf.variable_scope(\"conv_one\") as scope:\n",
    "\n",
    "        conv_one_filters = tf.get_variable(\n",
    "            \"conv/filters\", \n",
    "            shape=[3, 3, 3, 64], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv_one_biases = tf.get_variable(\n",
    "            \"conv/biases\", \n",
    "            shape=[1, 1, 1, 64], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "        attend_one_filters_one = tf.get_variable(\n",
    "            \"attend/filters_one\", \n",
    "            shape=[3, 3, 64, 16], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        attend_one_biases_one = tf.get_variable(\n",
    "            \"attend/biases_one\", \n",
    "            shape=[1, 1, 1, 16], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "        attend_one_filters_two = tf.get_variable(\n",
    "            \"attend/filters_two\", \n",
    "            shape=[3, 3, 64, 16], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        attend_one_biases_two = tf.get_variable(\n",
    "            \"attend/biases_two\", \n",
    "            shape=[1, 1, 1, 16], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"conv_two\") as scope:\n",
    "\n",
    "        conv_two_filters = tf.get_variable(\n",
    "            \"conv/filters\", \n",
    "            shape=[3, 3, 3, 64], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        conv_two_biases = tf.get_variable(\n",
    "            \"conv/biases\", \n",
    "            shape=[1, 1, 1, 64], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "        attend_two_filters_one = tf.get_variable(\n",
    "            \"attend/filters_one\", \n",
    "            shape=[3, 3, 64, 1], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        attend_two_biases_one = tf.get_variable(\n",
    "            \"attend/biases_one\", \n",
    "            shape=[1, 1, 1, 1], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "        attend_two_filters_two = tf.get_variable(\n",
    "            \"attend/filters_two\", \n",
    "            shape=[3, 3, 64, 1], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        attend_two_biases_two = tf.get_variable(\n",
    "            \"attend/biases_two\", \n",
    "            shape=[1, 1, 1, 1], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "    with tf.variable_scope(\"dense\") as scope:\n",
    "\n",
    "        dense_weights = tf.get_variable(\n",
    "            \"dense/weights\", \n",
    "            shape=[64, 1000], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.contrib.layers.xavier_initializer())\n",
    "        dense_biases = tf.get_variable(\n",
    "            \"dense/biases\", \n",
    "            shape=[1000], \n",
    "            dtype=tf.float32, \n",
    "            initializer=tf.zeros_initializer())\n",
    "\n",
    "    image_feed = tf.placeholder(\n",
    "        tf.float32, \n",
    "        name=\"image_feed\", \n",
    "        shape=[None, 57, 57, 3])\n",
    "    label_feed = tf.placeholder(\n",
    "        tf.int32, \n",
    "        name=\"label_feed\", \n",
    "        shape=[None, 1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with g.as_default():\n",
    "    \n",
    "    layer_one = tf.nn.relu(\n",
    "        tf.nn.conv2d(\n",
    "            image_feed,\n",
    "            conv_one_filters,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + conv_one_biases)\n",
    "    \n",
    "    attend_one_one = tf.nn.softmax(\n",
    "        tf.nn.conv2d(\n",
    "            layer_one,\n",
    "            attend_one_filters_one,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + attend_one_biases_one)\n",
    "    \n",
    "    attend_one_two = tf.nn.softmax(\n",
    "        tf.nn.conv2d(\n",
    "            layer_one,\n",
    "            attend_one_filters_two,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + attend_one_biases_two)\n",
    "    \n",
    "    full_attended_one = tf.reduce_sum(\n",
    "        tf.expand_dims(tf.expand_dims(layer_one, axis=3), axis=4) * \n",
    "        tf.expand_dims(tf.expand_dims(attend_one_one, axis=3), axis=5) *\n",
    "        tf.expand_dims(tf.expand_dims(attend_one_two, axis=4), axis=5),\n",
    "        axis=[1, 2])\n",
    "    \n",
    "    layer_two = tf.nn.relu(\n",
    "        tf.nn.conv2d(\n",
    "            image_feed,\n",
    "            conv_two_filters,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + conv_two_biases)\n",
    "    \n",
    "    attend_two_one = tf.nn.softmax(\n",
    "        tf.nn.conv2d(\n",
    "            layer_two,\n",
    "            attend_two_filters_one,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + attend_two_biases_one)\n",
    "    \n",
    "    attend_two_two = tf.nn.softmax(\n",
    "        tf.nn.conv2d(\n",
    "            layer_two,\n",
    "            attend_two_filters_two,\n",
    "            [1, 1, 1, 1],\n",
    "            \"SAME\") + attend_two_biases_two)\n",
    "    \n",
    "    full_attended_two = tf.reduce_sum(\n",
    "        tf.expand_dims(tf.expand_dims(layer_two, axis=3), axis=4) * \n",
    "        tf.expand_dims(tf.expand_dims(attend_two_one, axis=3), axis=5) *\n",
    "        tf.expand_dims(tf.expand_dims(attend_two_two, axis=4), axis=5),\n",
    "        axis=[1, 2])\n",
    "    \n",
    "    logits = tf.tensordot(\n",
    "            tf.reduce_sum(full_attended_two, axis=[1, 2]),\n",
    "            dense_weights,\n",
    "            1) + dense_biases\n",
    "    prediction = tf.nn.softmax(logits)\n",
    "    loss = tf.reduce_sum(\n",
    "        tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=logits, \n",
    "            labels=label_feed))\n",
    "    gradient = tf.train.GradientDescentOptimizer(\n",
    "        0.001).minimize(loss)\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    \n",
    "g.finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: 434 Actual: 630 Loss 0.00\n",
      "Prediction: 617 Actual: 630 Loss 0.00\n",
      "Prediction: 136 Actual: 630 Loss 0.00\n",
      "Prediction: 505 Actual: 630 Loss 0.00\n",
      "Prediction: 730 Actual: 630 Loss 0.00\n",
      "Prediction: 653 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n",
      "Prediction: 809 Actual: 630 Loss 0.00\n"
     ]
    }
   ],
   "source": [
    "sess.run(init_op)\n",
    "for _i in range(20):\n",
    "    p, l, _g = sess.run(\n",
    "        [prediction, loss, gradient], \n",
    "        feed_dict={\"image_feed:0\": input_images, \n",
    "                   \"label_feed:0\": image_labels})\n",
    "    print(\n",
    "        \"Prediction: %d\" % np.argmax(p[0]), \n",
    "        \"Actual: %d\" % np.argmax(image_labels[0]),\n",
    "        \"Loss %.2f\" % l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
